<!DOCTYPE html>

 <html lang="en">
  <head>
      <meta charset="UTF-8">  
    <title> AI Sentience </title>


    <link href="../../essay.css"  rel="stylesheet">
    <link href="../../style3.css" rel="stylesheet">
  <!--  <link href="../../style.css" rel="stylesheet">
    -->
   </head>

  <body >
    <div class="apatitle-pg">
    
     
      <p style="text-align:center;">
	   <b> The Application of AI in Decision Making Roles </b> 
      <br>
<br>
      <br>
      Shivanshi Das
      <br>
      Allen ISD STEAM Center
      <br>
      Advanced Computer Science 2
      <br>
      David Ben-Yaakov
      <br>
      September 2, 2022
      <br>

</p>
       </div>
	<div class="question-col">          
	<b> Introduction</b>
<br>
	Artificial Intelligence (AI) has become a buzzword in the tech industry since its initial introduction in the 1950s and yet not many are aware of what exactly AI entails. An AI system is intelligent in that it works by traversing through large sets of labeled data with which the system is then able to search for trends and patterns and make predictions about future states. Such an advanced degree of pattern recognition and predictive modeling has not only resulted in some eerily humane chatbots but a series of applications in many fields, including healthcare and law enforcement. <br>

<b> Benefits of AI </b>
<br>

The benefits of AI in such fields are innumerable; from programs that automate the pre-authorization of insurance to those that follow up on unpaid bills, the application of AI to streamline administrative tasks saves both time and money for those involved. For reference, administrative tasks are estimated to constitute around 30% of all healthcare costs; with the use of AI, that 30% is lowered to the cost of the program and the minimal staff intervention in overseeing the tasks carried out by the programs (Intelligence, 2022).

<br>
<b> Detriments of AI in Healthcare </b>

<br>
However, it is important to note that regardless of the efficiency of any computer program, human oversight is a must in fields such as healthcare. A program is written by humans who are by no means an exception to human error such that there is no guarantee the predictions given by the model are as accurate as they should be. The use of AI is especially more problematic in critical decision-making settings because, to a large extent, an AI system is reflective of the data it uses such that any form of bias in the data will be inherited by the system as well. One instance of such bias can be seen in the American Heart Association Get with Guidelines - Heart Failure Risk Score in which patients identified as “non-black” are assigned three additional points in comparison to their Black counterparts ("Racial bias", n.d.). This is of concern, especially because patients who seek care less frequently will make up a smaller portion of the data such that historically marginalized populations who seek healthcare less frequently will continue to be marginalized as faulty tests raise the threshold for use of clinical resources by African American individuals.

<br>
<b> Detriments of AI in the Justice System</b>
<br>
The effects of prejudiced data are not limited to the field of healthcare; predictive policing algorithms, for example, are not much better than the inherently prejudiced AI systems used in healthcare. Such algorithms are based on arrest rates, and the problem is that, according to the US Department of Justice, Black individuals are twice as likely to be arrested as their non-Black counterparts (Heaven, 2020). With such numbers and algorithms that use such data, predictive policing algorithms create a self-enforcing loop in which historically marginalized groups are marginalized time by time.
<br>

<b> The "Sentient" in Sentient AI </b>
<br>

AI may not be sentient, but, in a more figurative sense, the persuasive effects it has on individuals in decision-making positions make it an almost sentient being in itself. While it can be argued that such algorithms are not meant to be used as an indisputable higher power, the problem is in that they unintentionally influence the individuals in charge of making decisions because that is simply how humans are. As seen in the Eliza effect, humans tend to trust any entity that exhibits any form of human behavior such that it is reasonable for individuals to trust the findings of an artificially “intelligent” program albeit subconsciously (Metz, 2022). The benefits of AI are endless; however, there is a gap between reality and the data being processed by AI-based algorithms, and, before such a gap can be filled, AI will continue to be as controversial as it is today.
<br>

      
   </div>
	<div class="question-col">
	  <p style="text-align:center;"><b> References</b></p>
	 
	  <div style=" padding: 10px; padding-left: 64px; text-indent: -60px;">
	    Heaven, W. D. (2020, December 10). Predictive policing algorithms are racist. they need to be dismantled. MIT Technology Review. Retrieved September 2, 2022, from <a href = "https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/"> https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/ </a><br></div>
	   <div style=" padding: 10px; padding-left: 64px; text-indent: -60px;">   
	     Intelligence, I. (2022, April 15). How the medical field is benefiting from AI in 2022 and beyond. Insider Intelligence. Retrieved September 2, 2022, from <a href = "https://www.insiderintelligence.com/insights/artificial-intelligence-healthcare/#:~:text=According%20to%20Insider%20Intelligence%2C%2030,and%20ultimately%20save%20them%20money."> https://www.insiderintelligence.com/insights/artificial-intelligence-healthcare/#:~:text=According%20to%20Insider%20Intelligence%2C%2030,and%20ultimately%20save%20them%20money. </a><br></div>
	    <div style=" padding: 10px; padding-left: 64px; text-indent: -60px;">   
	      Metz, C. (2022, August 5). A.I. is not sentient. why do people say it is? The New York Times. Retrieved September 2, 2022, from <a href = "https://www.nytimes.com/2022/08/05/technology/ai-sentient-google.html"> https://www.nytimes.com/2022/08/05/technology/ai-sentient-google.html </a><br></div>
	     <div style=" padding: 10px; padding-left: 64px; text-indent: -60px;">   
	  Racial bias in health care artificial intelligence. NIHCM. (n.d.). Retrieved September 2, 2022, from <a href ="https://nihcm.org/publications/artificial-intelligences-racial-bias-in-health-care"> https://nihcm.org/publications/artific\
	           ial-intelligences-racial-bias-in-health-care </a><br></div>
	  </div>

    <div class = "tab" style= "text-decoration: none;">
      <ul>
    <li><a href = "https://github.com/ShivanshiDas/ShivanshiDas.github.io">
      I LIVE HERE
    </a></li>
    </ul>
</div>
    </body>


  </html>
